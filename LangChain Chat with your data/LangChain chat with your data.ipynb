{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"secrets.env\", raise_error_if_not_found=True))\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Construction 157 (2024) 105187\n",
      "Available online 11 November 2023\n",
      "0926-5805/Â© 2023 Elsevier B.V. All rights reserved.Review \n",
      "Generative AI design for building structures \n",
      "Wenjie Liaoa, Xinzheng Lua,*, Yifan Feib, Yi Gub, Yuli Huanga \n",
      "aKey Laboratory of Civil Engineering Safety and Durability of Ministry of Education, Tsinghua University, Beijing 100084, China \n",
      "bBeijing Engineering Research Center of Steel and Concrete Composite Structures, Tsinghua University, Beijing 100084, China \n",
      "\n",
      "source: Data/Generative AI design for building structures.pdf\n",
      "page: 0\n"
     ]
    }
   ],
   "source": [
    "# import the loader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# load the document\n",
    "loader = PyPDFLoader(file_path=\"Data/Generative AI design for building structures.pdf\")\n",
    "pages = loader.load()\n",
    "firstPage = pages[0]\n",
    "\n",
    "# see what's inside\n",
    "print(firstPage.page_content[:500])\n",
    "print(\"\")\n",
    "\n",
    "# see the metadata of this first page\n",
    "for k, v in firstPage.metadata.items():\n",
    "\tprint(f\"{k}: {v}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube Loader\n",
    "\n",
    "Something is wrong with yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain.document_loaders.generic import GenericLoader\\nfrom langchain.document_loaders.parsers import OpenAIWhisperParser\\nfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\\n\\n# url of the video\\n# url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\\nurl=\"https://youtu.be/eHzoTLwx01E?si=xLkpwI4rvuW1FEpJ\"\\n\\n# local path to save audio\\npath = \"Data/youtube/\"\\n\\n# build the generic loader with the youtube loader and the parser\\nloader = GenericLoader(\\n\\tblob_loader=YoutubeAudioLoader(\\n\\t\\turls=[url], #NB: urls argument must be a list\\n\\t\\tsave_dir=path\\n\\t),\\n\\tblob_parser=OpenAIWhisperParser()\\n)\\n\\n# load the youtube audio\\naudioDoc = loader.load()\\n\\n# see what it understood\\nprint(audioDoc[:500])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "# url of the video\n",
    "# url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "url=\"https://youtu.be/eHzoTLwx01E?si=xLkpwI4rvuW1FEpJ\"\n",
    "\n",
    "# local path to save audio\n",
    "path = \"Data/youtube/\"\n",
    "\n",
    "# build the generic loader with the youtube loader and the parser\n",
    "loader = GenericLoader(\n",
    "\tblob_loader=YoutubeAudioLoader(\n",
    "\t\turls=[url], #NB: urls argument must be a list\n",
    "\t\tsave_dir=path\n",
    "\t),\n",
    "\tblob_parser=OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "# load the youtube audio\n",
    "audioDoc = loader.load()\n",
    "\n",
    "# see what it understood\n",
    "print(audioDoc[:500])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# url for the loader\n",
    "url = \"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\"\n",
    "\n",
    "# create the loader\n",
    "loader = WebBaseLoader(web_path=url)\n",
    "\n",
    "# load the page content\n",
    "webDoc = loader.load()\n",
    "\n",
    "# print the page content\n",
    "# print(webDoc[0].page_content[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"secrets.env\", raise_error_if_not_found=True))\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prt(x):\n",
    "\tprint(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursive splitting from text1 = ['abcdefghijklmnopqrstuvwxyz']\n",
      "character splitting from text1 = ['abcdefghijklmnopqrstuvwxyz']\n",
      "\n",
      "recursive splitting from text2 = ['abcdefghijklmnopqrstuvwxyz', 'qrstuvwxyzabcdefg']\n",
      "character splitting from text2 = ['abcdefghijklmnopqrstuvwxyz', 'qrstuvwxyzabcdefg']\n",
      "\n",
      "recursive splitting from text3 = ['a b c d e f g h i j k l m', 'i j k l m n o p q r s t u', 'q r s t u v w x y z']\n",
      "character splitting from text3 = ['a b c d e f g h i j k l m', 'i j k l m n o p q r s t u', 'q r s t u v w x y z']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 26\n",
    "chunk_overlap = 10\n",
    "\n",
    "recursiveSplitter = RecursiveCharacterTextSplitter(\n",
    "\tchunk_size = chunk_size,\n",
    "\tchunk_overlap = chunk_overlap,\n",
    ")\n",
    "\n",
    "characterSplitter = CharacterTextSplitter(\n",
    "\tchunk_size = chunk_size,\n",
    "\tchunk_overlap = chunk_overlap,\n",
    "\tseparator = \"\"\n",
    ")\n",
    "\n",
    "# first example\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(f\"recursive splitting from text1 = {recursiveSplitter.split_text(text1)}\")\n",
    "print(f\"character splitting from text1 = {characterSplitter.split_text(text1)}\\n\")\n",
    "\n",
    "# second example\n",
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "print(f\"recursive splitting from text2 = {recursiveSplitter.split_text(text2)}\")\n",
    "print(f\"character splitting from text2 = {characterSplitter.split_text(text2)}\\n\")\n",
    "\n",
    "# third example\n",
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "print(f\"recursive splitting from text3 = {recursiveSplitter.split_text(text3)}\")\n",
    "print(f\"character splitting from text3 = {characterSplitter.split_text(text3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
